#!/usr/bin/env python3
"""
SDXL Models Download Script for RunPod
–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ SDXL –º–æ–¥–µ–ª—ñ –Ω–∞ persistent volume
"""

import os
import torch
from diffusers import StableDiffusionXLImg2ImgPipeline
import time

def setup_environment():
    """–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"""
    os.environ["TRANSFORMERS_CACHE"] = "/runpod-volume/cache"
    os.environ["HF_HOME"] = "/runpod-volume/cache"
    os.environ["TORCH_HOME"] = "/runpod-volume/cache"
    
    print("üåç Environment variables set")
    print(f"Cache directory: {os.environ['HF_HOME']}")

def check_gpu():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ GPU"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"‚úÖ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        return True
    else:
        print("‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞!")
        return False

def download_model(model_name, model_id, model_path):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É –º–æ–¥–µ–ª—å"""
    print(f"\nüîΩ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {model_name}...")
    print(f"Model ID: {model_id}")
    print(f"Save path: {model_path}")
    
    start_time = time.time()
    
    try:
        # Download model
        pipeline = StableDiffusionXLImg2ImgPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16,
            use_safetensors=True,
            cache_dir="/runpod-volume/cache"
        )
        
        # Save to persistent volume
        pipeline.save_pretrained(model_path)
        
        # Check model size
        total_size = sum(
            os.path.getsize(os.path.join(dirpath, filename))
            for dirpath, dirnames, filenames in os.walk(model_path)
            for filename in filenames
        ) / (1024**3)  # Convert to GB
        
        load_time = time.time() - start_time
        
        print(f"‚úÖ {model_name} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!")
        print(f"   –†–æ–∑–º—ñ—Ä: {total_size:.1f}GB")
        print(f"   –ß–∞—Å: {load_time:.1f}s")
        
        # Free memory
        del pipeline
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {model_name}: {e}")
        return False

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    print("üè∞ MyNeuralKingdom - SDXL Models Downloader")
    print("=" * 50)
    
    # Setup
    setup_environment()
    
    if not check_gpu():
        print("‚ö†Ô∏è GPU –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –∞–ª–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–æ–¥–æ–≤–∂—É—î—Ç—å—Å—è...")
    
    # Models to download
    models = {
        "epicrealism_xl": "stablediffusionapi/epic-realism-xl",
        "realvis_xl_lightning": "SG161222/RealVisXL_V5.0_Lightning", 
        "juggernaut_xl": "RunDiffusion/Juggernaut-XL-v9"
    }
    
    print(f"\nüìö –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {len(models)} SDXL –º–æ–¥–µ–ª–µ–π...")
    
    successful = 0
    failed = 0
    total_start_time = time.time()
    
    for model_name, model_id in models.items():
        model_path = f"/runpod-volume/models/{model_name}"
        
        # Check if already exists
        if os.path.exists(model_path) and os.listdir(model_path):
            print(f"‚è≠Ô∏è {model_name} –≤–∂–µ —ñ—Å–Ω—É—î, –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ...")
            successful += 1
            continue
        
        # Download model
        if download_model(model_name, model_id, model_path):
            successful += 1
        else:
            failed += 1
    
    total_time = time.time() - total_start_time
    
    # Summary
    print(f"\nüìä –ü—ñ–¥—Å—É–º–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:")
    print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ: {successful}/{len(models)}")
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∏: {failed}/{len(models)}")
    print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {total_time/60:.1f} —Ö–≤–∏–ª–∏–Ω")
    
    if successful == len(models):
        print("\nüéâ –í—Å—ñ –º–æ–¥–µ–ª—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        print("üöÄ MyNeuralKingdom –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–±–æ—Ç–∏!")
    else:
        print(f"\n‚ö†Ô∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏")
    
    # Check total size
    models_dir = "/runpod-volume/models"
    if os.path.exists(models_dir):
        total_size = sum(
            os.path.getsize(os.path.join(dirpath, filename))
            for dirpath, dirnames, filenames in os.walk(models_dir)
            for filename in filenames
        ) / (1024**3)
        print(f"üíæ –ó–∞–≥–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª–µ–π: {total_size:.1f}GB")

if __name__ == "__main__":
    main()