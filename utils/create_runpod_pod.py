#!/usr/bin/env python3
"""
RunPod Pod Creator for SDXL Image Enhancement Pipeline
Automatically creates and configures RunPod GPU instance
"""

import os
import sys
import requests
from dotenv import load_dotenv
import json

# Load environment variables
load_dotenv(".env")

class RunPodCreator:
    def __init__(self):
        self.api_key = os.getenv("RUNPOD_API_KEY")
        self.endpoint = "https://api.runpod.io/graphql"
        
        # Updated configurations based on actual RunPod availability
        self.gpu_configs = {
            "A40": {
                "gpu_type": "NVIDIA A40",
                "recommended": True,
                "price_range": "$0.40/hr",
                "performance": "Excellent (48GB VRAM) üåü"
            },
            "RTX6000Ada": {
                "gpu_type": "NVIDIA RTX 6000 Ada Generation",
                "recommended": True,
                "price_range": "$0.77/hr",
                "performance": "Excellent (48GB VRAM)"
            },
            "RTXA6000": {
                "gpu_type": "NVIDIA RTX A6000",
                "recommended": True,
                "price_range": "$0.49/hr",
                "performance": "Very Good (48GB VRAM)"
            },
            "RTX4090": {
                "gpu_type": "NVIDIA GeForce RTX 4090",
                "recommended": False,
                "price_range": "$0.69/hr",
                "performance": "Good (24GB VRAM limit)"
            }
        }
        
        # Docker images for different setups
        self.docker_images = {
            "pytorch": "runpod/pytorch:2.1.1-py3.10-cuda12.1.1-devel-ubuntu22.04",
            "automatic1111": "runpod/stable-diffusion:web-ui-10.2.1",
            "custom": "your-custom-image"
        }

    def check_api_key(self):
        """Verify API key is configured"""
        if not self.api_key:
            print("‚ùå RunPod API key not found!")
            print("üìù Please set RUNPOD_API_KEY in your .env file")
            print("üîó Get your API key from: https://runpod.io/console/user/settings")
            return False
        return True

    def get_headers(self):
        """Get request headers with API key"""
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def show_recommendations(self):
        """Show GPU and storage recommendations"""
        print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á –î–õ–Ø SDXL –ú–û–î–ï–õ–ï–ô:")
        print("="*50)
        
        print("\nüíª GPU:")
        for name, config in self.gpu_configs.items():
            status = "‚úÖ –†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–û" if config["recommended"] else "‚ö†Ô∏è  –û–ë–ú–ï–ñ–ï–ù–û"
            print(f"  {status} {name}")
            print(f"    üí∞ –¶—ñ–Ω–∞: {config['price_range']}")
            print(f"    ‚ö° –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: {config['performance']}")
        
        print("\nüíæ STORAGE:")
        print("  üìÅ Container Disk: 15-20GB (—Ç—ñ–ª—å–∫–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º–∏)")
        print("  üóÑÔ∏è  Network Volume: 40-60GB (–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–û!)")
        print("     ‚Ä¢ –°—Ç–≤–æ—Ä—ñ—Ç—å Network Storage –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º")
        print("     ‚Ä¢ –ü–æ—Å—Ç—ñ–π–Ω–µ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π")
        print("     ‚Ä¢ –ú–µ–Ω—à—ñ –≤–∏–º–æ–≥–∏ –¥–æ Container Disk")
        print("     ‚Ä¢ https://console.runpod.io/user/storage")
        print("\nüéØ –ü–û–¢–û–ß–ù–ê –î–û–°–¢–£–ü–ù–Ü–°–¢–¨: HIGH –¥–ª—è A40, RTX 6000 Ada!")
        print("üí° Network Storage –≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ –¥–∏—Å–∫–æ–≤–∏–º –ø—Ä–æ—Å—Ç–æ—Ä–æ–º!")

    def get_user_config(self):
        """Interactive configuration"""
        print("\n‚öôÔ∏è  –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –ü–û–î–£:")
        print("="*30)
        
        # GPU selection
        print("\n1. –û–±–µ—Ä—ñ—Ç—å GPU:")
        gpu_options = list(self.gpu_configs.keys())
        for i, gpu in enumerate(gpu_options, 1):
            status = "üåü" if self.gpu_configs[gpu]["recommended"] else "  "
            print(f"  {status} {i}. {gpu}")
        
        while True:
            try:
                gpu_choice = int(input(f"\n–ìPU (1-{len(gpu_options)}): ")) - 1
                selected_gpu = gpu_options[gpu_choice]
                break
            except (ValueError, IndexError):
                print("‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä, —Å–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑")
        
        # Storage configuration
        print(f"\n2. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ö–æ–≤–∏—â–∞:")
        print("   üìÅ Container Disk (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –¥–ª—è —Å–∏—Å—Ç–µ–º–∏)")
        container_disk = input("   –†–æ–∑–º—ñ—Ä (GB) –∞–±–æ Enter –¥–ª—è 15GB: ").strip()
        container_disk = int(container_disk) if container_disk else 15
        
        print("   üóÑÔ∏è  Network Volume ID (—è–∫—â–æ —Å—Ç–≤–æ—Ä–∏–ª–∏)")
        network_volume = input("   Volume ID –∞–±–æ Enter —â–æ–± –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏: ").strip()
        network_volume = network_volume if network_volume else None
        
        # Cloud type selection
        print(f"\n3. –¢–∏–ø —Ö–º–∞—Ä–∏:")
        print("   1. Secure Cloud (–¥–æ—Ä–æ–∂—á–µ, —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–µ)")
        print("   2. Community Cloud (–¥–µ—à–µ–≤—à–µ, –º–æ–∂–µ –±—É—Ç–∏ –º–µ–Ω—à —Å—Ç–∞–±—ñ–ª—å–Ω–æ)")
        
        cloud_choice = input("   –û–±–µ—Ä—ñ—Ç—å (1-2) –∞–±–æ Enter –¥–ª—è Community: ").strip()
        cloud_type = "SECURE" if cloud_choice == "1" else "COMMUNITY"
        
        # Docker image
        print(f"\n4. Docker –æ–±—Ä–∞–∑:")
        print("   1. PyTorch (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –¥–ª—è —Ü—å–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É)")
        print("   2. Automatic1111 (–≥–æ—Ç–æ–≤–∏–π WebUI)")
        
        docker_choice = input("   –û–±–µ—Ä—ñ—Ç—å (1-2) –∞–±–æ Enter –¥–ª—è PyTorch: ").strip()
        if docker_choice == "2":
            docker_image = self.docker_images["automatic1111"]
        else:
            docker_image = self.docker_images["pytorch"]
        
        return {
            "gpu_type": selected_gpu,
            "container_disk": container_disk,
            "network_volume": network_volume,
            "cloud_type": cloud_type,
            "docker_image": docker_image
        }

    def create_pod(self, config):
        """Create RunPod instance"""
        print(f"\nüöÄ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ–¥—É...")
        print(f"   GPU: {config['gpu_type']}")
        print(f"   Container: {config['container_disk']}GB")
        print(f"   Cloud: {config.get('cloud_type', 'COMMUNITY')}")
        if config.get('network_volume'):
            print(f"   Network Volume: {config['network_volume']}")
        else:
            print(f"   Network Volume: None")
        
        # GraphQL mutation for pod creation
        query = """
        mutation PodFindAndDeployOnDemand($input: PodFindAndDeployOnDemandInput!) {
          podFindAndDeployOnDemand(input: $input) {
            id
            imageName
            env
            machineId
            machine {
              podHostId
              gpuDisplayName
            }
          }
        }
        """
        
        variables = {
            "input": {
                "cloudType": config.get('cloud_type', 'COMMUNITY'),
                "gpuCount": 1,
                "gpuTypeId": config['gpu_type'],
                "containerDiskInGb": config['container_disk'],
                "name": "sdxl-enhancement-pipeline",
                "imageName": config['docker_image'],
                "ports": "3000/http,8888/http",
                "env": [
                    {"key": "RUNPOD_PROJECT", "value": "I-Model"},
                    {"key": "JUPYTER_ENABLE", "value": "1"}
                ]
            }
        }
        
        # Add network volume if provided
        if config.get('network_volume'):
            variables["input"]["dataCenterId"] = "EU-RO-1"  # Europe region for i-model-storage
            variables["input"]["networkVolumeId"] = config['network_volume']
        
        try:
            response = requests.post(
                self.endpoint,
                headers=self.get_headers(),
                json={"query": query, "variables": variables},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if "errors" in result:
                    print("‚ùå –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ–¥—É:")
                    for error in result["errors"]:
                        print(f"   {error['message']}")
                    return None
                
                pod_data = result["data"]["podFindAndDeployOnDemand"]
                print("‚úÖ –ü–æ–¥ —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ!")
                return pod_data
            else:
                print(f"‚ùå HTTP –ø–æ–º–∏–ª–∫–∞: {response.status_code}")
                print(response.text)
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è: {e}")
            return None

    def show_next_steps(self, pod_data):
        """Show what to do next"""
        pod_id = pod_data["id"]
        
        print(f"\nüéâ –£–°–ü–Ü–•! –ü–æ–¥ —Å—Ç–≤–æ—Ä–µ–Ω–æ!")
        print("="*40)
        print(f"üÜî Pod ID: {pod_id}")
        print(f"üíª GPU: {pod_data.get('machine', {}).get('gpuDisplayName', 'N/A')}")
        
        print(f"\nüìã –ù–ê–°–¢–£–ü–ù–Ü –ö–†–û–ö–ò:")
        print("1. –ó–∞–π–¥—ñ—Ç—å –≤ RunPod Console: https://runpod.io/console/pods")
        print("2. –ó–∞—á–µ–∫–∞–π—Ç–µ –ø–æ–∫–∏ –ø–æ–¥ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è (2-5 —Ö–≤–∏–ª–∏–Ω)")
        print("3. –í—ñ–¥–∫—Ä–∏–π—Ç–µ Terminal –∞–±–æ Jupyter")
        print("4. –ó–∞–ø—É—Å—Ç—ñ—Ç—å –∫–æ–º–∞–Ω–¥–∏:")
        print()
        print("   # –ö–ª–æ–Ω—É–≤–∞—Ç–∏ –ø—Ä–æ–µ–∫—Ç")
        print("   git clone https://github.com/your-repo/I-Model.git")
        print("   cd I-Model")
        print()
        print("   # –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ") 
        print("   pip install -r requirements.txt")
        print()
        print("   # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—ñ")
        print("   python utils/runpod_launcher.py --models epicrealism_xl")
        print()
        print("üåê WebUI –±—É–¥–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π –Ω–∞ –ø–æ—Ä—Ç—É 3000")
        print("üì± URL: https://[pod-id]-3000.proxy.runpod.net")

def main():
    """Main function"""
    print("üå•Ô∏è  RUNPOD CREATOR –¥–ª—è I, Model")
    print("="*50)
    print("–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è GPU –ø–æ–¥—É –¥–ª—è SDXL –º–æ–¥–µ–ª–µ–π")
    
    creator = RunPodCreator()
    
    # Check API key
    if not creator.check_api_key():
        sys.exit(1)
    
    # Show recommendations
    creator.show_recommendations()
    
    # Get user configuration
    config = creator.get_user_config()
    
    # Confirm creation
    print(f"\n‚ùì –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ–¥ –∑ —Ü–∏–º–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏? (y/N)")
    confirm = input().strip().lower()
    
    if confirm in ['y', 'yes', '—Ç–∞–∫', '–¥–∞']:
        pod_data = creator.create_pod(config)
        if pod_data:
            creator.show_next_steps(pod_data)
    else:
        print("‚ùå –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∫–∞—Å–æ–≤–∞–Ω–æ")

if __name__ == "__main__":
    main()
